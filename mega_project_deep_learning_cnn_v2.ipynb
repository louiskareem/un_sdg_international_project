{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the essential packages that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory and define the labels/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the image dimenions, all images will have height & width set to 200x200\n",
    "img_width, img_height = 200, 200\n",
    "\n",
    "# directory\n",
    "train_data_dir = 'organic_and_recyclable/'\n",
    "validation_data_dir = 'organic_and_recyclable/'\n",
    "\n",
    "# amount of samples that will be used in training and validation sets\n",
    "nb_train_samples = 400\n",
    "nb_validation_samples = 100\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the image is in the right format\n",
    "important to do this for every image neural network \n",
    "so, that the channels dont mix up, and that you dont get unexpected data\n",
    "\n",
    "ref: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "ref: https://www.codesofinterest.com/2017/09/keras-image-data-format.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first': #rgb\n",
    "    input_shape = (3, img_width, img_height) # 3 for 3 layers\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training and tests sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the training set\n",
    "train_data_gen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the test set\n",
    "test_data_gen = ImageDataGenerator(rescale = 1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 671 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generate the data\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir, target_size=(img_width, img_height), color_mode=\"rgb\", batch_size=batch_size, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 671 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generate the data\n",
    "validation_generator = test_data_gen.flow_from_directory(\n",
    "    validation_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can the 2 classes that is being mentioned above. Class O for Organic and Class R for Recyclable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'R': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create neural network with Sequential\n",
    "\n",
    "ref: https://www.ibm.com/cloud/learn/convolutional-neural-networks#toc-convolutio-JgBTyG9C\n",
    "ref: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "ref: https://www.tensorflow.org/tutorials/images/classification\n",
    "ref: https://keras.io/api/layers/convolution_layers/convolution2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create Sequential object\n",
    "model = Sequential()\n",
    "\n",
    "# add to the Convolutional layer (extract features from the images)\n",
    "# extract 32 features from the image, size of the search feature in pixels and iterate over all the pixels = 3, 3\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "# Activation function is relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# ading our max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# show what was the neural network has done\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://www.upgrad.com/blog/basic-cnn-architecture/\n",
    "ref: https://www.geeksforgeeks.org/activation-functions-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16928)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1083456   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,102,913\n",
      "Trainable params: 1,102,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# adding another convolutional layer and max pooling layer\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "# Activation function is relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# ading our max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# adding another convolutional layer and max pooling layer\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "# Activation function is relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# ading our max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# adding Our flattening Layer (flatten the image from 2d to 1d image)\n",
    "model.add(Flatten())\n",
    "\n",
    "# activate hidden layers which activate what the data is given then gives an output,\n",
    "model.add(Dense(64))\n",
    "\n",
    "# Activation function is relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# so it doesnt overfit, \n",
    "# if u want to make it faster so that it learns the images very well \n",
    "# then dont use dropouts\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# add the output layer, one output, whether 0 or 1, sigmoid makes this possible\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Activation function is sigmoid\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# show what was the neural network has done\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, first we compile then train the model using fit function\n",
    "\n",
    "ref: https://nickmccullum.com/python-deep-learning/convolutional-neural-network-tutorial/#training-the-convolutional-neural-network\n",
    "ref: https://docs.paperspace.com/machine-learning/wiki/accuracy-and-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.7064 - accuracy: 0.8508 - val_loss: 0.1121 - val_accuracy: 0.9600\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1937 - accuracy: 0.9341 - val_loss: 0.1573 - val_accuracy: 0.9300\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1845 - accuracy: 0.9319 - val_loss: 0.1666 - val_accuracy: 0.9500\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2320 - accuracy: 0.9032 - val_loss: 0.1034 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1779 - accuracy: 0.9404 - val_loss: 0.0779 - val_accuracy: 0.9800\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1877 - accuracy: 0.9240 - val_loss: 0.1375 - val_accuracy: 0.9500\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1795 - accuracy: 0.9437 - val_loss: 0.1704 - val_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1081 - accuracy: 0.9682 - val_loss: 0.1907 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2034 - accuracy: 0.9262 - val_loss: 0.0706 - val_accuracy: 0.9800\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1460 - accuracy: 0.9481 - val_loss: 0.0451 - val_accuracy: 0.9800\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1638 - accuracy: 0.9446 - val_loss: 0.1303 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1347 - accuracy: 0.9496 - val_loss: 0.1103 - val_accuracy: 0.9300\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1117 - accuracy: 0.9574 - val_loss: 0.0768 - val_accuracy: 0.9700\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0963 - accuracy: 0.9704 - val_loss: 0.0525 - val_accuracy: 0.9700\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1658 - accuracy: 0.9488 - val_loss: 0.0440 - val_accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0978 - accuracy: 0.9693 - val_loss: 0.0481 - val_accuracy: 0.9800\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1887 - accuracy: 0.9451 - val_loss: 0.1130 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0749 - accuracy: 0.9808 - val_loss: 0.0480 - val_accuracy: 0.9900\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1234 - accuracy: 0.9629 - val_loss: 0.0983 - val_accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.1445 - accuracy: 0.9336 - val_loss: 0.0237 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d1bdeb84c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model.\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # rmsprop\n",
    "\n",
    "# fit the generated model\n",
    "model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size,\n",
    "          epochs=epochs, validation_data=validation_generator,\n",
    "          validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is working fine. Validation loss started high then decreased, as for validation accuracy start low then increased. The model gives a validation accuracy of about 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always wise to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_three.h5')\n",
    "\n",
    "# with open('cnn_model_95_acc.pkl', 'wb') as file:\n",
    "#   pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating our model, we can see that our actual accuracy is 95.67% and our loss is around the 12.12\n",
    "\n",
    "ref: https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model\n",
    "ref: https://www.javacodemonk.com/difference-between-loss-accuracy-validation-loss-validation-accuracy-in-keras-ff358faa\n",
    "ref: https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 6s 424ms/step - loss: 0.2030 - accuracy: 0.9151\n",
      "accuracy= 0.9150521755218506\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(validation_generator, verbose=1)\n",
    "\n",
    "# print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
