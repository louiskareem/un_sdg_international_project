{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 200, 200\n",
    "train_data_dir = 'organic_and_recyclable/'\n",
    "validation_data_dir = 'organic_and_recyclable/'\n",
    "# how many samples you from the dataset to learn\n",
    "nb_train_samples = 1000\n",
    "nb_validation_samples = 800\n",
    "epochs = 10\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the image is in the right format\n",
    "# important to do this for every image neural network so that the channels dont mix up, and that you dont get unexpected data\n",
    "if K.image_data_format() == 'channels_first': #rgb\n",
    "    input_shape = (3, img_width, img_height) # 3 for 3 layers\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the training set\n",
    "train_data_gen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the test set\n",
    "test_data_gen = ImageDataGenerator(rescale = 1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a new generator\n",
    "# imagegen = ImageDataGenerator()\n",
    "# # load train data\n",
    "# train = imagegen.flow_from_directory(\"organic_and_recyclable/\", class_mode=\"binary\", shuffle=True, batch_size=1000, target_size=(200, 200))\n",
    "# # load val data\n",
    "# val = imagegen.flow_from_directory(\"organic_and_recyclable/\", class_mode=\"binary\", shuffle=True, batch_size=1000, target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5780 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generate training generator data\n",
    "# get the data and process it\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir, target_size=(img_width, img_height), color_mode=\"rgb\", batch_size=batch_size, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'R': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5780 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generate test generator data\n",
    "# get the data and process it\n",
    "validation_generator = test_data_gen.flow_from_directory(\n",
    "    validation_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make a neural network\n",
    "# create Sequential object\n",
    "model = Sequential()\n",
    "# add to the Convolutional network to extract features from the images\n",
    "# extract 32 features from the image, size of the search feature in pixels and iterate over all the pixels = 3, 3\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "# Activation function is relu\n",
    "model.add(Activation('relu'))\n",
    "# reduce image, to only get the features that i want\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# show what was the neural network has done\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 97, 97, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 46, 46, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16928)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1083456   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,102,913\n",
      "Trainable params: 1,102,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add to the Convolutional network to extract features from the images\n",
    "# extract 32 features from the image, size of the search feature in pixels and iterate over all the pixels = 3, 3\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# Activation function is relu\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# reduce image, to only get the features that i want\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# add to the Convolutional network to extract features from the images\n",
    "# extract 64 features from the image, size of the search feature in pixels and iterate over all the pixels = 3, 3\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# Activation function is relu\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# reduce image, to only get the features that i want\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# after getting the features,\n",
    "# flatten the image from 2d to 1d image\n",
    "model.add(Flatten())\n",
    "# activate hidden layers which activate what the data is given then gives an output,\n",
    "# add layers with 64 nodes, because we have 64 inputs\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "# so it doesnt overfit, if u want to make it faster so that it learns the images very well then dont use dropouts\n",
    "model.add(Dropout(0.5))\n",
    "# add dense layer, this becomes the output\n",
    "model.add(Dense(1))\n",
    "#\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# show what was the neural network has done\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.2787 - accuracy: 0.8712 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 42s 1s/step - loss: 0.1485 - accuracy: 0.9626 - val_loss: 0.1728 - val_accuracy: 0.9325\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1995 - accuracy: 0.9336 - val_loss: 0.1811 - val_accuracy: 0.9388\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 45s 1s/step - loss: 0.1589 - accuracy: 0.9471 - val_loss: 0.2822 - val_accuracy: 0.9538\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 48s 1s/step - loss: 0.1842 - accuracy: 0.9402 - val_loss: 0.1373 - val_accuracy: 0.9400\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.1411 - accuracy: 0.9492 - val_loss: 0.2094 - val_accuracy: 0.9425\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.1213 - accuracy: 0.9511 - val_loss: 0.1386 - val_accuracy: 0.9388\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 46s 1s/step - loss: 0.1033 - accuracy: 0.9545 - val_loss: 0.1329 - val_accuracy: 0.9613\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 45s 1s/step - loss: 0.1475 - accuracy: 0.9487 - val_loss: 0.1355 - val_accuracy: 0.9475\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1403 - accuracy: 0.9466 - val_loss: 0.1280 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2338e11b0d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model.\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # rmsprop\n",
    "\n",
    "# fit the generated model to put on this neural network\n",
    "# this will start the neural network and learn everything\n",
    "model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size,\n",
    "          epochs=epochs, validation_data=validation_generator,\n",
    "          validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# model.fit(train, epochs=epochs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_two.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('classifier_two.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if its working\n",
    "img_pred = image.load_img('organic_and_recyclable/rec.jpg', target_size=(200,200)) # O/O_4994  R/R_782\n",
    "# convert image to numpy array\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "#\n",
    "img_pred = np.expand_dims(img_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# predict the image from the validation set\n",
    "result = model.predict(img_pred/255)\n",
    "results = np.argmax(result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic\n"
     ]
    }
   ],
   "source": [
    "if results == 1:\n",
    "    prediction = 'Recyclable'\n",
    "else:\n",
    "    prediction = 'Organic'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
